#! /usr/bin/env python3
'''
    This script fully automates running tests, applying the fixer, and 
    validating that the fixed binaries no longer report bugs.
'''

from argparse import ArgumentParser
from copy import deepcopy
from enum import Enum, auto
from IPython import embed
from pathlib import Path
from pprint import pprint

import os
import shlex
import subprocess
import yaml

def assert_is_type(x, t):
    assert isinstance(x, t), f'"{x}" is type {type(x)}, not {t}'
 
def assert_is_path(*args):
    for x in args:
        assert_is_type(x, Path)


class ToolTypes(Enum):
    PMTEST = auto()
    PMEMCHECK = auto()
    PMDK_UNIT_TEST = auto()
    NONE = auto()

class ToolRunner:
    def __init__(self, exe_path, bc_path, tool_type):
        assert_is_path(exe_path, bc_path)
        assert_is_type(tool_type, ToolTypes)
        self.pmemcheck_path = Path(r'${PMCHK_BIN_DIR}/valgrind')
        assert self.pmemcheck_path.exists(), f'{str(self.pmemcheck_path)} does not exist!'
        self.exe_path = exe_path
        self.exe_fixed_path = Path(str(exe_path) + '.fixed')
        self.bc_path = bc_path
        self.tool_type = tool_type
        self.suite = exe_path.parent.name

    def target(self):
        return self.exe_path.name

    def in_suite(self, suite):
        if suite == 'all' or suite == self.suite:
            return True
        return False

    def _run_pmtest(self):
        return True

    def _run_pmemcheck(self):
        return True

    def _run_pmdk_unit_test(self):
        '''
            We get the trace from the log file.
        '''
        # Need to set the PATH so the scripts can find the pmemcheck tool
        new_env = deepcopy(os.environ)
        if 'LD_LIBRARY_PATH' not in new_env:
            new_env['LD_LIBRARY_PATH'] = f'{str(self.exe_path.parent)}'
        else:
            new_env['LD_LIBRARY_PATH'] += f':{str(self.exe_path.parent)}'
        new_env['PATH'] = f'{str(self.pmemcheck_path.parent)}:{new_env["PATH"]}'

        # 0. Cleanup old logs, if any.
        pmemcheck_log = self.exe_path.parent / 'pmemcheck0.log'
        if pmemcheck_log.exists():
            pmemcheck_log.unlink()

        # 1. Run initial test
        runtests_args = shlex.split(f'./RUNTESTS -b debug -p force-enable {self.exe_path.parent.name} -s TEST0')
        res = subprocess.run(runtests_args, cwd=self.exe_path.parent.parent, env=new_env)
        assert (res.returncode != 0), 'Test was successful, meaning no bugs!'
        assert pmemcheck_log.exists(), 'No pmemcheck log!'

        # 2. Get trace from log file
        assert pmemcheck_log.exists(), 'Log not created!'
        parse_script = Path(__file__).parent.absolute() / 'parse-trace'
        assert parse_script.exists(), 'parser not available!'
        trace_file = pmemcheck_log.parent / "pmemcheck0.trace"
        parse_args = shlex.split(f'{str(parse_script)} pmemcheck {str(pmemcheck_log)} -o {str(trace_file)}')
        res = subprocess.run(parse_args)
        res.check_returncode()
        assert trace_file.exists()

        # 3. Run the fixer script
        fixer_script = Path(__file__).parent.absolute() / 'apply-fixer'
        fixer_args = shlex.split(f'{str(fixer_script)} {str(self.bc_path)} {str(trace_file)} -o {str(self.exe_fixed_path)}')
        res = subprocess.run(fixer_args)
        res.check_returncode()

        # 4. Re-run the unit tests, see if we fixed it!
        runtests_args = shlex.split(
            f'./RUNTESTS -b fixed -p force-enable {self.exe_path.parent.name} -s TEST0')
        res = subprocess.run(runtests_args, cwd=self.exe_path.parent.parent, env=new_env)
        res.check_returncode()

        return True

    def run(self):
        print(f'{self.exe_path}: {self.tool_type.name}')
        if self.tool_type == ToolTypes.PMTEST:
            return self._run_pmtest()
        elif self.tool_type == ToolTypes.PMEMCHECK:
            return self._run_pmemcheck()
        elif self.tool_type == ToolTypes.PMDK_UNIT_TEST:
            return self._run_pmdk_unit_test()
        else:
            return False

def get_test_list():
    '''
        List of:
            (test_executable, test_bitcode, tool_to_use)
    '''
    exe_list = r'${TEST_EXE_LIST}'.split(';')
    bc_list = r'${TEST_BC_LIST}'.split(';')
    tool_list = r'${TEST_TOOL_LIST}'.split(';')
    test_list = [ (Path(x), Path(y), ToolTypes[z]) for x, y, z in 
                    zip(exe_list, bc_list, tool_list)]
    for x, y, _ in test_list:
        assert (f'{str(x)}.bc' == str(y)), 'EXE list and BC list not matching up!!!'
        assert x.exists(), f'{x} must be built!'
        assert y.exists(), f'{y} must be extracted!'

    suites = set([x[0].parent.name for x in test_list] + ['all'])

    return test_list, sorted(list(suites))

def run_test(exe, bc, tool, suite):
    # 1. Run the test and gather the initial trace.
    r = ToolRunner(exe, bc, tool)
    if not r.in_suite(suite):
        print(f'{r.target()} in suite {r.suite}, skipping')
        return

    success = r.run()
    if success:
        print(f'1. {r.target()} ran successfully.')
    else:
        raise Exception(f'{r.target()} failed!')
    
    # 2. Parse the trace.

    # 3. Apply the fix.

    # 4. Re-run the fixed test.

    # 5. Parse the trace from the fixed test.

    # 6. Assert that the bugs are fixed.


def run_all(args, test_list):
    for exe, bc, tool in test_list:
        run_test(exe, bc, tool, args.suite)

def main():
    test_list, suites = get_test_list()

    parser = ArgumentParser(description=(r'Verify the ${CMAKE_PROJECT_NAME} by '
        'running tests, applying fixes, then verifying all the bugs are gone.'))
    parser.add_argument('suite', type=str, choices=suites, default='all',
                        help='Which set of tests to run')
    args = parser.parse_args()

    run_all(args, test_list)


if __name__ == '__main__':
    main()